<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>fast.ai on Nikita Melkozerov</title><link>https://nikita.melkozerov.dev/tags/fast.ai/</link><description>Recent content in fast.ai on Nikita Melkozerov</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 23 Feb 2021 15:47:11 +0100</lastBuildDate><atom:link href="https://nikita.melkozerov.dev/tags/fast.ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Image Classification from scratch without a PhD</title><link>https://nikita.melkozerov.dev/posts/2021/02/image-classification-from-scratch-without-a-phd/</link><pubDate>Tue, 23 Feb 2021 15:47:11 +0100</pubDate><guid>https://nikita.melkozerov.dev/posts/2021/02/image-classification-from-scratch-without-a-phd/</guid><description>Hello folks!
Recently I trained a handwritten digit classifier using the MNIST dataset from scratch, and it was an eye-opening experience for me. What looked like magic to me before now is just a few mathematical concepts applied together. I was very excited about how simple the whole process was, and I want to share it with everyone who still wonders what kind of magic is happening inside.
All you need to know is a bit of python and a few concepts from high-school math.</description></item><item><title>Transfer Learning and ResNet: In search of a perfect batch size</title><link>https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/</link><pubDate>Wed, 06 Jan 2021 10:20:25 +0000</pubDate><guid>https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/</guid><description>&lt;p>TL;DR: &lt;em>batch size 32 is probably going to be a good default candidate for many cases.&lt;/em>&lt;/p>
&lt;p>In this post, we will observe how different batch sizes change learning metrics when we train a model using Transfer Learning and the fast.ai library. We will try to find out which batch sizes are good and which are better to be avoided.&lt;/p></description></item></channel></rss>