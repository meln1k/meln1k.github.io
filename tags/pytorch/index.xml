<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pytorch on Nikita Melkozerov</title><link>https://nikita.melkozerov.dev/tags/pytorch/</link><description>Recent content in pytorch on Nikita Melkozerov</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 24 Feb 2021 22:47:11 +0100</lastBuildDate><atom:link href="https://nikita.melkozerov.dev/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>Image Classification from scratch without a PhD</title><link>https://nikita.melkozerov.dev/posts/2021/02/image-classification-from-scratch-without-a-phd/</link><pubDate>Wed, 24 Feb 2021 22:47:11 +0100</pubDate><guid>https://nikita.melkozerov.dev/posts/2021/02/image-classification-from-scratch-without-a-phd/</guid><description>Hello folks!
Recently I trained a handwritten digit classifier using the MNIST dataset from scratch, and it was an eye-opening experience for me. What looked like magic to me before now is just a few mathematical concepts applied together. I was very excited about how simple the whole process was, and I want to share it with everyone who still wonders what kind of magic is happening inside.
All you need to know is a bit of python and a few concepts from high-school math.</description></item></channel></rss>