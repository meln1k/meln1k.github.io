<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Transfer Learning and ResNet: In search of a perfect batch size | Nikita Melkozerov</title><meta name=keywords content="fast.ai,deep learning"><meta name=description content="How different batch sizes affect learning when using ResNet image classifiers."><meta name=author content><link rel=canonical href=https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/><link href=/assets/css/stylesheet.min.1eef9c740af75b4e5f773d9d5f757e03e3df71f3a308e73070cc73d55a59a7d7.css integrity="sha256-Hu+cdAr3W05fdz2dX3V+A+PfcfOjCOcwcMxz1VpZp9c=" rel="preload stylesheet" as=style><link rel=icon href=https://nikita.melkozerov.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nikita.melkozerov.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nikita.melkozerov.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://nikita.melkozerov.dev/apple-touch-icon.png><link rel=mask-icon href=https://nikita.melkozerov.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-59947059-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Transfer Learning and ResNet: In search of a perfect batch size"><meta property="og:description" content="How different batch sizes affect learning when using ResNet image classifiers."><meta property="og:type" content="article"><meta property="og:url" content="https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/"><meta property="article:published_time" content="2021-01-06T10:20:25+00:00"><meta property="article:modified_time" content="2021-01-06T10:20:25+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Transfer Learning and ResNet: In search of a perfect batch size"><meta name=twitter:description content="How different batch sizes affect learning when using ResNet image classifiers."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nikita.melkozerov.dev/posts/"},{"@type":"ListItem","position":2,"name":"Transfer Learning and ResNet: In search of a perfect batch size","item":"https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Transfer Learning and ResNet: In search of a perfect batch size","name":"Transfer Learning and ResNet: In search of a perfect batch size","description":"TL;DR: batch size 32 is probably going to be a good default candidate for many cases.\nIn this post, we will observe how different batch sizes change learning metrics when we train …","keywords":["fast.ai","deep learning"],"articleBody":"TL;DR: batch size 32 is probably going to be a good default candidate for many cases.\nIn this post, we will observe how different batch sizes change learning metrics when we train a model using Transfer Learning and the fast.ai library. We will try to find out which batch sizes are good and which are better to be avoided.\nGetting the dataset Recently I was going through the awesome fast.ai deep learning course, and in one of the lectures we were building a classifier that can recognize cats and dogs. I wanted to build one too, and since I live in Hamburg I decided to go with some birds one can see there. Fortunately, there was a post by Luca Feuerriegel where I found the names of some of the species: European Robin, Marsh Tit, Eurasian Blackbird, Eurasian Nuthatch, Eurasian Jay, Eurasian Wren, Hawfinch, Bullfinch, Common Starling, Greylag Goose, Barnacle Goose, Meadow Pipit, Common Wood Pigeon, Mistle Thrush.\nTo collect the dataset, I used the bing image search to get images of every bird mentioned above. I’m not going to publish the collected images since I have doubts about violating copyright, however, you can download the source code of the notebook and run the experiment yourself.\nAfter I collected the dataset, I did a few training iterations and cleaned the dataset using the ImageClassifierCleaner tool in the fast.ai library.\nIn the end, I ended up with 2017 pictures representing 14 different species of birds, which should be good enough to train the model fast and not overfit too quickly.\nTraining the model To obtain the results we’re going to experiment with 3 ResNet architectures: ResNet50, ResNet34, and ResNet18. For each architecture, we will train the model 10 times with batch sizes of 128, 64, 32, 16, 8, and 4. We will also train the model for 10 epochs for each combination of the architecture and batch size.\nWe’re also going to apply a few transformations and data augmentation steps to avoid overfitting: randomly cropping and resizing the images, and applying a standard set of batch augmentation (aug_transforms()):\n1 2 3 4 5 6 7  birdsDB = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=1337), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())   The other parameters will be left to default. We will also use a CSVLogger callback to save the learning metrics to the CSV files which we will analyze later.\n1 2 3 4  def train(arch, batch_size, index): dls = birdsDB.dataloaders(path, bs=batch_size) learn = cnn_learner(dls, architectures[arch], metrics=error_rate, cbs=[ShowGraphCallback, CSVLogger(fname=f'birds-{arch}-bs{batch_size}-{index}.csv')]).to_fp16() learn.fine_tune(10)   We will also train with half-precision to fit ResNet50 with 128 batch size into my GPU.\nFinally this is our nested loop where we will try different parameters:\n1 2 3 4 5 6  for arch in ['rn50', 'rn34', 'rn18']: for bs in [128, 64, 32, 16, 8, 4]: for index in range(10): train(arch, bs, index) torch.cuda.empty_cache() gc.collect()   It is worth noting that this loop took around 6 hours to finish, so be patient if you would like to experiment yourself :)\nAnalyzing the results After waiting for a few hours, we finally have all 180 CSV files ready for analysis. Yay!\nLet’s dig into them.\nFirst we would need a function to parse the CSV file and convert it into a pandas dataframe:\n1 2 3 4 5 6 7  def loadLog(bs: int, arch: str, idx: int) - pd.DataFrame: df = pd.read_csv(f\"birds-{arch}-bs{bs}-{idx}.csv\") # change the time to seconds # since no training epoch took more than 1 minute  # we will cheat and simply trim the minutes away df['time'] = df.apply(lambda df: int(df['time'].split(':')[1]), axis=1) return df   Then, because we have 10 dataframes per each combination of a batch size and an architecture, we will merge them together and calculate the average:\n1 2 3 4  def loadMergedLog(bs: int, arch: str) - pd.DataFrame: dfs = map(lambda idx: loadLog(bs, arch, idx), range(10)) merged = pd.concat(dfs) return merged.groupby(merged.index).mean()   Finally, we need a function that will plot the results:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def plotResults(arch: str, y_axis: str): fig, ax = plt.subplots() fig.set_size_inches(20,15) blockSizes = [128, 64, 32, 16, 8, 4] for bs in blockSizes: frame = loadMergedLog(bs, arch) plt.plot(frame['epoch'], frame[y_axis]) ax.legend(blockSizes); ax.legend(blockSizes); plt.xlim(0,9) plt.show()   With all this in place, let’s see how the batch size was affecting the training:\nResNet50 Let’s start with the error rate:\nHere we see that batch sizes 4 and 8 are not that good, and 32 gave us the lowest error after 10 epochs of training.\nNow let’s look at the training time:\nUnsurprisingly, batch sizes 4 and 8 were slow due to copying overhead, while batch sizes of 32 and 64 were the fastest. Interestingly, a batch size of 128 was also slower than 32 and 64.\nResNet34 With a reduced number of layers the model error rate seems to follow the same pattern as before: batch size 32 looking better than the others (however not that much) and batch size 4 again showed the lowest performance.\nSpeaking of training time we see the same picture: batch sizes of 32 and 64 being the fastest, and 4 being the slowest.\nInitially, the learning performance doubles when we double the batch size (bs16 is twice as fast as bs8, and bs8 is twice as fast as bs4), and stabilizes around 32 and 62 images per batch.\nResNet18 When we train the model using an even smaller ResNet architecture, our previous results are confirmed again:\nLearning was the fastest with batch size 32, and the performance of all three 16, 32, and 64 batch sizes are very similar.\nResults We trained the classifier on the natural images resized to 224 pixels, and discovered that batch size 32 was often surpassing other candidates in terms of learning speed and error rate.\nThis means that it is probably going to be a good default candidate when we try to analyze natural images and want to iterate quickly, for example when wanting to clean up the dataset.\nBatch sizes of 8 and less are probably better be avoided if your images are small due to high overhead on data transfer.\nTraining with a batch size of 128 was slower and a bit less accurate, so it might not be the ideal candidate to start with.\n","wordCount":"1040","inLanguage":"en","datePublished":"2021-01-06T10:20:25Z","dateModified":"2021-01-06T10:20:25Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/"},"publisher":{"@type":"Organization","name":"Nikita Melkozerov","logo":{"@type":"ImageObject","url":"https://nikita.melkozerov.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://nikita.melkozerov.dev/ accesskey=h title="Nikita Melkozerov (Alt + H)">Nikita Melkozerov</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://nikita.melkozerov.dev/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://nikita.melkozerov.dev/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://nikita.melkozerov.dev/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Transfer Learning and ResNet: In search of a perfect batch size</h1><div class=post-description>How different batch sizes affect learning when using ResNet image classifiers.</div><div class=post-meta>January 6, 2021&nbsp;·&nbsp;5 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#getting-the-dataset aria-label="Getting the dataset">Getting the dataset</a></li><li><a href=#training-the-model aria-label="Training the model">Training the model</a></li><li><a href=#analyzing-the-results aria-label="Analyzing the results">Analyzing the results</a><ul><ul><li><a href=#resnet50 aria-label=ResNet50>ResNet50</a></li><li><a href=#resnet34 aria-label=ResNet34>ResNet34</a></li><li><a href=#resnet18 aria-label=ResNet18>ResNet18</a></li></ul></ul></li><li><a href=#results aria-label=Results>Results</a></li></ul></div></details></div><div class=post-content><p>TL;DR: <em>batch size 32 is probably going to be a good default candidate for many cases.</em></p><p>In this post, we will observe how different batch sizes change learning metrics when we train a model using Transfer Learning and the fast.ai library. We will try to find out which batch sizes are good and which are better to be avoided.</p><h1 id=getting-the-dataset>Getting the dataset<a hidden class=anchor aria-hidden=true href=#getting-the-dataset>#</a></h1><p>Recently I was going through the awesome <a href=https://course.fast.ai/>fast.ai deep learning course</a>, and in one of the lectures we were building a classifier that can recognize cats and dogs. I wanted to build one too, and since I live in Hamburg I decided to go with some birds one can see there. Fortunately, there was a <a href=https://myzoneisbirding.wordpress.com/2018/05/01/hamburg-germany-08-04-15-04-2018/>post by Luca Feuerriegel</a> where I found the names of some of the species: <em>European Robin</em>, <em>Marsh Tit</em>, <em>Eurasian Blackbird</em>, <em>Eurasian Nuthatch</em>, <em>Eurasian Jay</em>, <em>Eurasian Wren</em>, <em>Hawfinch</em>, <em>Bullfinch</em>, <em>Common Starling</em>, <em>Greylag Goose</em>, <em>Barnacle Goose</em>, <em>Meadow Pipit</em>, <em>Common Wood Pigeon</em>, <em>Mistle Thrush</em>.</p><p>To collect the dataset, I used the bing image search to get images of every bird mentioned above. I&rsquo;m not going to publish the collected images since I have doubts about violating copyright, however, you can download the <a href=https://github.com/meln1k/deep-learning-experiments/blob/main/block-size-and-learning-rate/HamburgBirds.ipynb>source code of the notebook</a> and run the experiment yourself.</p><p>After I collected the dataset, I did a few training iterations and cleaned the dataset using the <code>ImageClassifierCleaner</code> tool in the fast.ai library.</p><p>In the end, I ended up with 2017 pictures representing 14 different species of birds, which should be good enough to train the model fast and not overfit too quickly.</p><h1 id=training-the-model>Training the model<a hidden class=anchor aria-hidden=true href=#training-the-model>#</a></h1><p>To obtain the results we&rsquo;re going to experiment with 3 ResNet architectures: ResNet50, ResNet34, and ResNet18. For each architecture, we will train the model 10 times with batch sizes of 128, 64, 32, 16, 8, and 4. We will also train the model for 10 epochs for each combination of the architecture and batch size.</p><p>We&rsquo;re also going to apply a few transformations and data augmentation steps to avoid overfitting: randomly cropping and resizing the images, and applying a standard set of batch augmentation (<code>aug_transforms()</code>):</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>birdsDB <span style=color:#f92672>=</span> DataBlock(
    blocks<span style=color:#f92672>=</span>(ImageBlock, CategoryBlock),
    get_items<span style=color:#f92672>=</span>get_image_files,
    splitter<span style=color:#f92672>=</span>RandomSplitter(valid_pct<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>, seed<span style=color:#f92672>=</span><span style=color:#ae81ff>1337</span>),
    get_y<span style=color:#f92672>=</span>parent_label,
    item_tfms<span style=color:#f92672>=</span>RandomResizedCrop(<span style=color:#ae81ff>224</span>, min_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>),
    batch_tfms<span style=color:#f92672>=</span>aug_transforms())</code></pre></td></tr></table></div></div><p>The other parameters will be left to default. We will also use a <code>CSVLogger</code> callback to save the learning metrics to the CSV files which we will analyze later.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train</span>(arch, batch_size, index):
    dls <span style=color:#f92672>=</span> birdsDB<span style=color:#f92672>.</span>dataloaders(path, bs<span style=color:#f92672>=</span>batch_size)
    learn <span style=color:#f92672>=</span> cnn_learner(dls, architectures[arch], metrics<span style=color:#f92672>=</span>error_rate, cbs<span style=color:#f92672>=</span>[ShowGraphCallback, CSVLogger(fname<span style=color:#f92672>=</span>f<span style=color:#e6db74>&#39;birds-{arch}-bs{batch_size}-{index}.csv&#39;</span>)])<span style=color:#f92672>.</span>to_fp16()
    learn<span style=color:#f92672>.</span>fine_tune(<span style=color:#ae81ff>10</span>)</code></pre></td></tr></table></div></div><p>We will also train with half-precision to fit ResNet50 with 128 batch size into my GPU.</p><p>Finally this is our nested loop where we will try different parameters:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>for</span> arch <span style=color:#f92672>in</span> [<span style=color:#e6db74>&#39;rn50&#39;</span>, <span style=color:#e6db74>&#39;rn34&#39;</span>, <span style=color:#e6db74>&#39;rn18&#39;</span>]:
    <span style=color:#66d9ef>for</span> bs <span style=color:#f92672>in</span> [<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>4</span>]:
        <span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>10</span>):
            train(arch, bs, index)
            torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>empty_cache()
            gc<span style=color:#f92672>.</span>collect()</code></pre></td></tr></table></div></div><p>It is worth noting that this loop took around 6 hours to finish, so be patient if you would like to experiment yourself :)</p><h1 id=analyzing-the-results>Analyzing the results<a hidden class=anchor aria-hidden=true href=#analyzing-the-results>#</a></h1><p>After waiting for a few hours, we finally have all 180 CSV files ready for analysis. Yay!</p><p>Let&rsquo;s dig into them.</p><p>First we would need a function to parse the CSV file and convert it into a pandas dataframe:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>loadLog</span>(bs: int, arch: str, idx: int) <span style=color:#f92672>-&gt;</span> pd<span style=color:#f92672>.</span>DataFrame:
    df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(f<span style=color:#e6db74>&#34;birds-{arch}-bs{bs}-{idx}.csv&#34;</span>)
    <span style=color:#75715e># change the time to seconds</span>
    <span style=color:#75715e># since no training epoch took more than 1 minute </span>
    <span style=color:#75715e># we will cheat and simply trim the minutes away</span>
    df[<span style=color:#e6db74>&#39;time&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> df: int(df[<span style=color:#e6db74>&#39;time&#39;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;:&#39;</span>)[<span style=color:#ae81ff>1</span>]), axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>return</span> df</code></pre></td></tr></table></div></div><p>Then, because we have 10 dataframes per each combination of a batch size and an architecture, we will merge them together and calculate the average:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>loadMergedLog</span>(bs: int, arch: str) <span style=color:#f92672>-&gt;</span> pd<span style=color:#f92672>.</span>DataFrame:
    dfs <span style=color:#f92672>=</span> map(<span style=color:#66d9ef>lambda</span> idx: loadLog(bs, arch, idx), range(<span style=color:#ae81ff>10</span>))
    merged <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat(dfs)
    <span style=color:#66d9ef>return</span> merged<span style=color:#f92672>.</span>groupby(merged<span style=color:#f92672>.</span>index)<span style=color:#f92672>.</span>mean()</code></pre></td></tr></table></div></div><p>Finally, we need a function that will plot the results:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plotResults</span>(arch: str, y_axis: str):
    fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()

    fig<span style=color:#f92672>.</span>set_size_inches(<span style=color:#ae81ff>20</span>,<span style=color:#ae81ff>15</span>)

    blockSizes <span style=color:#f92672>=</span> [<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>4</span>]

    <span style=color:#66d9ef>for</span> bs <span style=color:#f92672>in</span> blockSizes:
        frame <span style=color:#f92672>=</span> loadMergedLog(bs, arch)
        plt<span style=color:#f92672>.</span>plot(frame[<span style=color:#e6db74>&#39;epoch&#39;</span>], frame[y_axis])
        ax<span style=color:#f92672>.</span>legend(blockSizes);

    ax<span style=color:#f92672>.</span>legend(blockSizes);
    plt<span style=color:#f92672>.</span>xlim(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>9</span>)
    plt<span style=color:#f92672>.</span>show()</code></pre></td></tr></table></div></div><p>With all this in place, let&rsquo;s see how the batch size was affecting the training:</p><h3 id=resnet50>ResNet50<a hidden class=anchor aria-hidden=true href=#resnet50>#</a></h3><p>Let&rsquo;s start with the error rate:</p><p><img src=/images/transfer-learning-batch-size-experiment/rn50-errors.png alt="ResNet50 errors"></p><p>Here we see that batch sizes 4 and 8 are not that good, and 32 gave us the lowest error after 10 epochs of training.</p><p>Now let&rsquo;s look at the training time:</p><p><img src=/images/transfer-learning-batch-size-experiment/rn50-time.png alt="ResNet50 training time"></p><p>Unsurprisingly, batch sizes 4 and 8 were slow due to copying overhead, while batch sizes of 32 and 64 were the fastest. Interestingly, a batch size of 128 was also slower than 32 and 64.</p><h3 id=resnet34>ResNet34<a hidden class=anchor aria-hidden=true href=#resnet34>#</a></h3><p>With a reduced number of layers the model error rate seems to follow the same pattern as before: batch size 32 looking better than the others (however not that much) and batch size 4 again showed the lowest performance.</p><p><img src=/images/transfer-learning-batch-size-experiment/rn34-errors.png alt="ResNet34 errors"></p><p>Speaking of training time we see the same picture: batch sizes of 32 and 64 being the fastest, and 4 being the slowest.</p><p><img src=/images/transfer-learning-batch-size-experiment/rn34-time.png alt="ResNet34 training time"></p><p>Initially, the learning performance doubles when we double the batch size (bs16 is twice as fast as bs8, and bs8 is twice as fast as bs4), and stabilizes around 32 and 62 images per batch.</p><h3 id=resnet18>ResNet18<a hidden class=anchor aria-hidden=true href=#resnet18>#</a></h3><p>When we train the model using an even smaller ResNet architecture, our previous results are confirmed again:</p><p><img src=/images/transfer-learning-batch-size-experiment/rn18-errors.png alt="ResNet18 errors"></p><p><img src=/images/transfer-learning-batch-size-experiment/rn18-time.png alt="ResNet18 training time"></p><p>Learning was the fastest with batch size 32, and the performance of all three 16, 32, and 64 batch sizes are very similar.</p><h1 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h1><p>We trained the classifier on the natural images resized to 224 pixels, and discovered that batch size 32 was often surpassing other candidates in terms of learning speed and error rate.</p><p>This means that it is probably going to be a good default candidate when we try to analyze natural images and want to iterate quickly, for example when wanting to clean up the dataset.</p><p>Batch sizes of 8 and less are probably better be avoided if your images are small due to high overhead on data transfer.</p><p>Training with a batch size of 128 was slower and a bit less accurate, so it might not be the ideal candidate to start with.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://nikita.melkozerov.dev/tags/fast.ai/>fast.ai</a></li><li><a href=https://nikita.melkozerov.dev/tags/deep-learning/>deep learning</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://nikita.melkozerov.dev/>Nikita Melkozerov</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})});var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>