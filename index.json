[{"content":"TL;DR: batch size 32 is probably going to be a good default candidate for many cases.\nIn this post, we will observe how different batch sizes change learning metrics when we train a model using Transfer Learning and the fast.ai library. We will try to find out which batch sizes are good and which are better to be avoided.\nGetting the dataset Recently I was going through the awesome fast.ai deep learning course, and in one of the lectures we were building a classifier that can recognize cats and dogs. I wanted to build one too, and since I live in Hamburg I decided to go with some birds one can see there. Fortunately, there was a post by Luca Feuerriegel where I found the names of some of the species: European Robin, Marsh Tit, Eurasian Blackbird, Eurasian Nuthatch, Eurasian Jay, Eurasian Wren, Hawfinch, Bullfinch, Common Starling, Greylag Goose, Barnacle Goose, Meadow Pipit, Common Wood Pigeon, Mistle Thrush.\nTo collect the dataset, I used the bing image search to get images of every bird mentioned above. I\u0026rsquo;m not going to publish the collected images since I have doubts about violating copyright, however, you can download the source code of the notebook and run the experiment yourself.\nAfter I collected the dataset, I did a few training iterations and cleaned the dataset using the ImageClassifierCleaner tool in the fast.ai library.\nIn the end, I ended up with 2017 pictures representing 14 different species of birds, which should be good enough to train the model fast and not overfit too quickly.\nTraining the model To obtain the results we\u0026rsquo;re going to experiment with 3 ResNet architectures: ResNet50, ResNet34, and ResNet18. For each architecture, we will train the model 10 times with batch sizes of 128, 64, 32, 16, 8, and 4. We will also train the model for 10 epochs for each combination of the architecture and batch size.\nWe\u0026rsquo;re also going to apply a few transformations and data augmentation steps to avoid overfitting: randomly cropping and resizing the images, and applying a standard set of batch augmentation (aug_transforms()):\n1 2 3 4 5 6 7  birdsDB = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=1337), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())   The other parameters will be left to default. We will also use a CSVLogger callback to save the learning metrics to the CSV files which we will analyze later.\n1 2 3 4  def train(arch, batch_size, index): dls = birdsDB.dataloaders(path, bs=batch_size) learn = cnn_learner(dls, architectures[arch], metrics=error_rate, cbs=[ShowGraphCallback, CSVLogger(fname=f\u0026#39;birds-{arch}-bs{batch_size}-{index}.csv\u0026#39;)]).to_fp16() learn.fine_tune(10)   We will also train with half-precision to fit ResNet50 with 128 batch size into my GPU.\nFinally this is our nested loop where we will try different parameters:\n1 2 3 4 5 6  for arch in [\u0026#39;rn50\u0026#39;, \u0026#39;rn34\u0026#39;, \u0026#39;rn18\u0026#39;]: for bs in [128, 64, 32, 16, 8, 4]: for index in range(10): train(arch, bs, index) torch.cuda.empty_cache() gc.collect()   It is worth noting that this loop took around 6 hours to finish, so be patient if you would like to experiment yourself :)\nAnalyzing the results After waiting for a few hours, we finally have all 180 CSV files ready for analysis. Yay!\nLet\u0026rsquo;s dig into them.\nFirst we would need a function to parse the CSV file and convert it into a pandas dataframe:\n1 2 3 4 5 6 7  def loadLog(bs: int, arch: str, idx: int) -\u0026gt; pd.DataFrame: df = pd.read_csv(f\u0026#34;birds-{arch}-bs{bs}-{idx}.csv\u0026#34;) # change the time to seconds # since no training epoch took more than 1 minute  # we will cheat and simply trim the minutes away df[\u0026#39;time\u0026#39;] = df.apply(lambda df: int(df[\u0026#39;time\u0026#39;].split(\u0026#39;:\u0026#39;)[1]), axis=1) return df   Then, because we have 10 dataframes per each combination of a batch size and an architecture, we will merge them together and calculate the average:\n1 2 3 4  def loadMergedLog(bs: int, arch: str) -\u0026gt; pd.DataFrame: dfs = map(lambda idx: loadLog(bs, arch, idx), range(10)) merged = pd.concat(dfs) return merged.groupby(merged.index).mean()   Finally, we need a function that will plot the results:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def plotResults(arch: str, y_axis: str): fig, ax = plt.subplots() fig.set_size_inches(20,15) blockSizes = [128, 64, 32, 16, 8, 4] for bs in blockSizes: frame = loadMergedLog(bs, arch) plt.plot(frame[\u0026#39;epoch\u0026#39;], frame[y_axis]) ax.legend(blockSizes); ax.legend(blockSizes); plt.xlim(0,9) plt.show()   With all this in place, let\u0026rsquo;s see how the batch size was affecting the training:\nResNet50 Let\u0026rsquo;s start with the error rate:\nHere we see that batch sizes 4 and 8 are not that good, and 32 gave us the lowest error after 10 epochs of training.\nNow let\u0026rsquo;s look at the training time:\nUnsurprisingly, batch sizes 4 and 8 were slow due to copying overhead, while batch sizes of 32 and 64 were the fastest. Interestingly, a batch size of 128 was also slower than 32 and 64.\nResNet34 With a reduced number of layers the model error rate seems to follow the same pattern as before: batch size 32 looking better than the others (however not that much) and batch size 4 again showed the lowest performance.\nSpeaking of training time we see the same picture: batch sizes of 32 and 64 being the fastest, and 4 being the slowest.\nInitially, the learning performance doubles when we double the batch size (bs16 is twice as fast as bs8, and bs8 is twice as fast as bs4), and stabilizes around 32 and 62 images per batch.\nResNet18 When we train the model using an even smaller ResNet architecture, our previous results are confirmed again:\nLearning was the fastest with batch size 32, and the performance of all three 16, 32, and 64 batch sizes are very similar.\nResults We trained the classifier on the natural images resized to 224 pixels, and discovered that batch size 32 was often surpassing other candidates in terms of learning speed and error rate.\nThis means that it is probably going to be a good default candidate when we try to analyze natural images and want to iterate quickly, for example when wanting to clean up the dataset.\nBatch sizes of 8 and less are probably better be avoided if your images are small due to high overhead on data transfer.\nTraining with a batch size of 128 was slower and a bit less accurate, so it might not be the ideal candidate to start with.\n","permalink":"https://nikita.melkozerov.dev/posts/2021/01/transfer-learning-and-resnet-in-search-of-a-perfect-batch-size/","summary":"\u003cp\u003eTL;DR: \u003cem\u003ebatch size 32 is probably going to be a good default candidate for many cases.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn this post, we will observe how different batch sizes change learning metrics when we train a model using Transfer Learning and the fast.ai library. We will try to find out which batch sizes are good and which are better to be avoided.\u003c/p\u003e","title":"Transfer Learning and ResNet: In search of a perfect batch size"},{"content":"How to prepare your FoundationDB cluster to run it in production and set up process classes to achieve maximum performance.\nFoundationDB is an outstanding database and it is a joy to use it as a developer. However, when it comes to running FDB in production, it is not always clear how many instances are needed and what classes should be assigned to processes. As of June 2019, FoundationDB doesn\u0026rsquo;t (yet) have a \u0026ldquo;smart\u0026rdquo; tool that can automatically set the layout of the FDB cluster, and it is important to set the layout manually to achieve decent performance.\nIn this post, I\u0026rsquo;ll writte about the best practices for configuring FDB cluster which I discovered while experimenting with the database and reading FoundationDB forums.\nRoles, Classes, and Processes in FoundationDB FoundationDB server processes are identical binaries, but it is possible to assign a process to a specific class or a role to prioritize a specific workload. The difference between a class and a role is that assigning a class to a process specifies preference to recruit one of the corresponding roles (based on how good a particular role fits to a class), and assigning a role will result in a process preferring a single workload. The relationships between classes and roles are defined in the Locality.cpp file.\nOut of clutter, find simplicity While no one prevents assigning a single role to a process, it is more flexible to assign storage, transaction and stateless classes to processes. Let\u0026rsquo;s look at them more closely:\nStorage class: best fit for the storage role, worst fit for the transaction log role. Other roles won\u0026rsquo;t be recruited in a process with this class.\nTransaction class: good fit for the transaction log role, okay fit for the proxy, resolver, log router, cluster controller roles, worst fit for the storage role.\nStateless class: good fit for the proxy, master, resolver, log router, cluster controller, data distributor, and ratekeeper processes. Storage and transaction log roles won\u0026rsquo;t be assigned to the stateless process.\nWhen FDB tries to figure out which role it will recruit in a process, the fitness priority is used: best fit \u0026gt; good fit \u0026gt; okay fit \u0026gt; unset fit \u0026gt; worst fit \u0026gt; never assign. For example, if there are two processes which both have a transaction and a stateless class, the proxy role will be assigned to the stateless class since it fits better, even though transaction class is also suitable for this role.\nPlease note that assigning a role to the process will be treated as a class with the best fit for that role.\nEvery individual has a role to play for the betterment of our cluster So, if a process will be recruited for a particular role, what will it do? Let\u0026rsquo;s look at them one by one:\n Process with the storage role is responsible for storing key/value b-trees and serving reads to clients. It provides a consistent database snapshot for the last 5 seconds. A typical FDB cluster would have ~ 80-90% of all processes recruited as storage. The transaction log process keeps an append-only log of mutations for ~ 7 seconds before the changes are pulled by the storage process, then deletes them. If a storage process is not able to pull the changes in time, the disk space used by log will grow. The proxy sits between the client and transactional authority and coordinates the actions along the write transaction path. It also gives out recent read versions to the client. The master keeps track of the commit version, assigns commit versions to transactions to provide global ordering. The resolver checks transactions and aborts them if they\u0026rsquo;re conflicting. The data distributor is responsible for distributing data across shards. The ratekeeper limits the transaction rate to prevent cluster overload. The cluster controller knows the cluster configuration, provides it to new clients and reconfigures the cluster in the event of network disruption. The log router will be recruited in remote datacenters for the purpose of supporting the log replication.  Now that we know more about the classes, roles, and processes, let\u0026rsquo;s see what resource requirements different roles have.\nRequirements and resources Different process roles consume different resources such as CPU, IOPS, network bandwidth and RAM, and we need to be careful to not create resource contention that will lead to reduced performance.\nThe transaction Log is both IOPS1 and bandwidth2 hungry, and it\u0026rsquo;s important to dedicate a whole disk for it. Memory consumption is ~ 1GB3.\nThe storage is not IOPS hungry but it can saturate the CPU, so it\u0026rsquo;s better to not run the storage role in one process with others. If your SSD is fast enough, having more than one storage processes will utilize it better. It consumes less bandwidth than tLog or proxy, but it usually requires ~ 4GB of memory on average3.\nThe proxy is bandwidth2 \u0026amp; CPU hungry, and it is important to give this role enough CPU to keep the latencies low.\nThe resolver is involved in checking conflict ranges and if you don\u0026rsquo;t have conflicts then CPU consumption will be low4. No high bandwidth or high IOPS consumption is expected, but the memory consumption can around 1GB3.\nThe rest of the stateless processes do not consume any significant resources and can be deployed without restrictions.\nBased on the requirements above, there is a set of recommendations:\n Don\u0026rsquo;t run tLog and storage on a single disk. Don\u0026rsquo;t run anything else in a single process that has storage or proxy roles since they\u0026rsquo;re CPU hungry. Run each proxy on a different host. It might be useful to dedicate a separate host for tLog due to its bandwidth consumption. Don\u0026rsquo;t leave unspecified processes as FDB will recruit a storage role there by default5, and this can increase latency for other roles in this process.  These are not hard rules but rather recommendations that should improve the performance of your cluster. For example, if a proxy is consuming the whole CPU core but the network is not saturated, it makes sense to run another proxy process on the same host.\nBuilding the cluster Given that we understand more about roles and their requirements, let\u0026rsquo;s see what might be reasonable cluster layouts.\n2-node replication If we want to tolerate a single machine failure (and make progress after such failure), we need 3 machines with 2 copy replication. However, for performance reasons, we should not share disks between tLog and storage roles. It means that we should have 6 separate disks. Often, cloud providers will give only one disk per node, that\u0026rsquo;s why we need at least six different nodes to prevent performance penalties in the event of failure.\nA minimal Layout #1: 6 nodes, 2 processes in each node:\n tLog master tLog cluster_controller tLog stateless storage proxy storage proxy storage stateless  In this layout, we try to utilize the network bandwidth as much as possible by placing tLogs and proxies on different nodes, and at the same time, we don\u0026rsquo;t have a performance loss in case of failure because we have extra tLog and storage processes. You can easily scale this cluster by adding more storage processes, and adding more tLog, proxies, and resolver if they\u0026rsquo;re overloaded.\nA minimal Layout #2: 5 nodes, 2 processes in each node:\n tLog master tLog cluster_controller storage proxy storage proxy storage stateless  Here we use fewer nodes, however, if tLog fails FDB will relocate the missing tLog to the same process together with a storage role. This will degrade the performance and increase latencies until the node is back.\nPlease note that the ratio of tLog : storage is not optimal here and it\u0026rsquo;s done this way purely due to fault tolerance concerns. Usually, you need more storage processes than tLog processes. It depends on your workload though, if you have lots of heavy writes, then having more tLog processes is better.\nAlso, don\u0026rsquo;t forget to configure three coordinators to keep the cluster running in the event of a node failure.\n3-node replication If you\u0026rsquo;re unsure about the reliability of the available hosts, it is possible to use 3-node replication. Again, I\u0026rsquo;m making this layout given that only 1 disk is available per host, therefore we need to have 4 hosts for each tLog and storage role.\nA minimal Layout #3: 8 nodes, 2 processes in each node:\n tLog master tLog cluster_controller tLog stateless tLog stateless storage proxy storage proxy storage proxy storage resolution  With this layout we don\u0026rsquo;t share a node between the proxy and the tLog, disks aren\u0026rsquo;t shared between stateful processes, and every process has a set class so FDB won\u0026rsquo;t spawn a storage process where we wouldn\u0026rsquo;t expect it. We already have quite some tLog roles here, so to scale this cluster we should add more storage nodes.\nThat\u0026rsquo;s all, folks. I hope these layouts will make it easier to bootstrap a FoundationDB cluster. Do you have other cool ideas about the possible cluster layouts? Please share them in the comments!\n  https://forums.foundationdb.org/t/production-deployment/522/4?u=meln1k \u0026#x21a9;\u0026#xfe0e;\n https://forums.foundationdb.org/t/production-optimizations/601/11?u=meln1k \u0026#x21a9;\u0026#xfe0e;\n https://forums.foundationdb.org/t/constrained-ram-in-an-application-development-environment/347/4?u=meln1k \u0026#x21a9;\u0026#xfe0e;\n https://forums.foundationdb.org/t/configuring-foundationdb-to-use-more-than-one-resolver/1414/2?u=meln1k \u0026#x21a9;\u0026#xfe0e;\n https://forums.foundationdb.org/t/production-optimizations/601/13?u=meln1k \u0026#x21a9;\u0026#xfe0e;\n  ","permalink":"https://nikita.melkozerov.dev/posts/2019/06/building-a-foundationdb-cluster-roles-classes-and-processes/","summary":"\u003cp\u003eHow to prepare your FoundationDB cluster to run it in production and set up process\nclasses to achieve maximum performance.\u003c/p\u003e","title":"Building a FoundationDB Cluster: Roles, Classes, and Processes"}]